{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"Load Taxonomy Labels from Uniprot.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"4RFY3SPiE5Jn","colab_type":"text"},"source":["# Load taxonomy labels from uniprot\n","\n","This notebook will query uniprot or uniref for genes that are in a fasta file (or alignment a2m file) and output the taxonomy for those genes.\n","\n","1. Query uniref for each gene name (one-at-a-time) to get the taxonomy ID. \n","   Save results to the filesystem for caching.\n","2. Use the NCBITaxa service to load the phylogeny \n","\n","Requires `sequence_space_data.zip` from https://evcouplings.org/3Dseq\n","\n","Requires: NCBITaxa, BioPython, and Pandas"]},{"cell_type":"code","metadata":{"id":"EkIXlQuUE5Jo","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%config InlineBackend.figure_format='png'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1qa1whLE5Js","colab_type":"code","colab":{}},"source":["from ete3 import NCBITaxa\n","import requests\n","import xml.etree.ElementTree as ET\n","from Bio import SeqIO\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QW8veP-CE5Jv","colab_type":"code","colab":{}},"source":["UNIREF_URL = 'https://www.uniprot.org/uniref/{0}.xml'\n","UNIPROT_URL = 'https://www.uniprot.org/uniprot/{0}.xml'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"176QYVgdE5Jy","colab_type":"text"},"source":["# Functions to query genes from Uniref and Uniprot"]},{"cell_type":"code","metadata":{"id":"A7-5Q5L7E5Jy","colab_type":"code","colab":{}},"source":["def getAndSaveExternalRecord(url, output_file):\n","    '''\n","    Request a uniref xml record from the uniref website. \n","    Save to filesystem for caching purposes.\n","    Returns the record text.\n","    '''\n","    response = requests.get(url)\n","    if response.ok:\n","        if len(response.text) < 1:\n","            raise IOError('{0} had invalid response: {1}'.format(url, 'returned length is zero'))\n","        \n","        f = open(output_file, 'w')\n","        f.write(response.text)\n","        f.close()\n","        return response.text\n","    else:\n","        raise IOError('{0} had invalid response: {1}'.format(url, response))\n","    return None\n","\n","def getTaxonomyIdFromUniref(unirefid, output_dir, local_cache_only = False, recurse=True):\n","    '''\n","    Load taxonomy from local filesystem (if available) or from uniref directly.\n","    Throws an IOError if the uniref ID returns a 404 or other error when\n","    querying uniref. Returns the taxonomy id as a string.\n","    '''\n","    filename = '{0}/{1}.xml'.format(output_dir, unirefid)\n","    \n","    try:\n","        xmlroot = ET.parse(filename).getroot()\n","        for element in xmlroot.iter():\n","            if 'type' in element.attrib and element.attrib['type'] == 'NCBI taxonomy':\n","                return element.attrib['value']\n","    except:\n","        if local_cache_only == False:\n","            if recurse:\n","                getAndSaveExternalRecord(\n","                    UNIREF_URL.format(unirefid), filename\n","                )\n","                return getTaxonomyIdFromUniref(unirefid, output_dir)\n","            else:\n","                raise IOError('Unable to load uniref {0} after 2 attempts'.format(unirefid))\n","        raise IOError('{0}.xml does not exist and local_cache_only set to True'.format(unirefid))\n","        \n","def getTaxonomyIdFromUniprot(uniprotid, output_dir, local_cache_only = False, recurse=True):\n","    '''\n","    Load taxonomy from local filesystem (if available) or from uniprot directly.\n","    Throws an IOError if the uniref ID returns a 404 or other error when\n","    querying uniprot. Returns the taxonomy id as a string.\n","    '''\n","    filename = '{0}/{1}.xml'.format(output_dir, uniprotid)\n","    \n","    try:\n","        xmlroot = ET.parse(filename).getroot()\n","        for element in xmlroot.iter():\n","            if 'type' in element.attrib and element.attrib['type'] == 'NCBI Taxonomy':\n","                return element.attrib['id']\n","    except:\n","        if local_cache_only == False:\n","            if recurse:\n","                getAndSaveExternalRecord(\n","                    UNIPROT_URL.format(uniprotid), filename\n","                )\n","                return getTaxonomyIdFromUniprot(uniprotid, output_dir, recurse=False) #only try once\n","            else:\n","                raise IOError('Unable to load uniprot {0} after 2 attempts'.format(uniprotid))\n","        raise IOError('{0}.xml does not exist and local_cache_only set to True'.format(uniprotid))\n","    \n","        \n","def getSequencenameTaxonomyidHM(alignment_filename, output_dir, local_cache_only = False):\n","    '''\n","    Loads taxonomy ids for all sequences in an alignment. Returns a\n","    hashmap with sequence name as key and the tax id as value. Sequences that\n","    do not have a valid uniref ID are omitted from the returned hashmap.\n","    \n","    local_cache_only: If set to try, uniref will not be queried and only the\n","                      local file system will be used (useful to force caching)\n","    returns: a Dataframe with two columns (1) seq_record and (2) tax_id\n","    '''\n","    loaderrorcount = 0\n","    \n","    toreturn = {\n","        'seq_record': [],\n","        'seq_name': [],\n","        'sequence': [],\n","        'tax_id': []\n","    }\n","    sequences = list(SeqIO.parse(alignment_filename, 'fasta'))\n","    for seq_record in sequences:\n","        tax_id = None\n","        if 'up|' in seq_record.name:\n","            uniprotid = seq_record.name.split('|')[1]\n","            try:\n","                tax_id = getTaxonomyIdFromUniprot(\n","                    uniprotid, output_dir, local_cache_only=local_cache_only\n","                )\n","            except IOError as e:\n","                loaderrorcount += 1\n","                print('{0}: {1}'.format(loaderrorcount, e))\n","            \n","        elif 'UniRef' in seq_record.name:\n","            seqname = seq_record.name\n","            if 'ur|' in seq_record.name:\n","                seqname = seqname.split('|')[2]\n","                \n","            unirefid = seqname.split('/')[0]\n","            try:\n","                tax_id = getTaxonomyIdFromUniref(\n","                    unirefid, output_dir, local_cache_only=local_cache_only\n","                )\n","            except IOError as e:\n","                loaderrorcount += 1\n","                print('{0}: {1}'.format(loaderrorcount, e))\n","        else:\n","            print('warning: unable to determine sequence record type: {0}'.format(seq_record.name))\n","            \n","        if tax_id:\n","            toreturn['seq_record'].append( seq_record )\n","            toreturn['seq_name'].append( seq_record.name )\n","            toreturn['sequence'].append( str(seq_record.seq) )\n","            toreturn['tax_id'].append( tax_id )\n","        \n","    return pd.DataFrame.from_dict(toreturn)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rFrSFUKKE5J0","colab_type":"text"},"source":["# Query taxonomy from NCBITaxa"]},{"cell_type":"code","metadata":{"id":"ibhk7z1GE5J1","colab_type":"code","colab":{}},"source":["ncbi = NCBITaxa()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSxjKY4-E5J4","colab_type":"code","colab":{}},"source":["def loadTaxonomyLineage(tax_ids):\n","    rank_sequencevalue_hm = { #will become part of the dataframe\n","        'superkingdom': [],\n","        'phylum': [],\n","        'genus': [],\n","        'class': [],\n","        'subphylum': [],\n","        'family': [],\n","        'order': [],\n","        'species': [],\n","    }\n","    for tax_id in tax_ids:\n","        try:\n","            lineage = ncbi.get_lineage(int(tax_id))\n","            lineageid_name_dict = ncbi.get_taxid_translator(lineage) #dict: key=lineageid, value=sequence value\n","            lineageid_rank_dict = ncbi.get_rank(lineage)\n","            rank_lineageid_dict = dict((v,k) for k,v in lineageid_rank_dict.items())\n","\n","            for rank in rank_sequencevalue_hm:\n","                sequence_value_for_rank = None\n","                if rank in rank_lineageid_dict:\n","                    lineageid = rank_lineageid_dict[rank]\n","                    sequence_value_for_rank = lineageid_name_dict[lineageid]\n","                rank_sequencevalue_hm[rank].append(\n","                    sequence_value_for_rank\n","                )\n","        except ValueError as e:\n","            print('Warning: {0}'.format(str(e)))\n","    return pd.DataFrame.from_dict(rank_sequencevalue_hm)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y2ywVwJfE5J_","colab_type":"text"},"source":["# Load and Save AAC6 Lineages"]},{"cell_type":"code","metadata":{"id":"QHQH7nQWE5KA","colab_type":"code","colab":{}},"source":["ALIGNMENT_DIR = 'data.AAC6'\n","SEQUENCE_ALIGNMENT = ALIGNMENT_DIR+'/44883374318b63406a7415d2f4d4cfc1_b0.4.a2m'\n","CACHE_DIR = 'UNIREF_RECORDS_AAC6'\n","OUTPUT_FILENAME = ALIGNMENT_DIR+'/AAC6_NATURAL_TAXONOMY.csv'\n","\n","#Load taxonomy IDS. \n","#  Note:  loaded 3740 uniref records and saved them to the file system.\n","#         unable to recover 253 of the IDs in the AAC6 natural alignment (404 response)\n","#         2 records were manually loaded due to retry errors (connection issues?)\n","aac6_df = getSequencenameTaxonomyidHM(SEQUENCE_ALIGNMENT, CACHE_DIR, local_cache_only=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUAz2ULJE5KI","colab_type":"code","colab":{}},"source":["#output to csv\n","pd.concat([aac6_df, loadTaxonomyLineage(aac6_df.tax_id)], \n","          axis=1, \n","          sort=False).drop('seq_record', axis=1).to_csv(\n","    \n","    OUTPUT_FILENAME, sep='\\t', index=False\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t70mKsTSE5KL","colab_type":"text"},"source":["# Load and Save PSE1 Lineages"]},{"cell_type":"code","metadata":{"id":"Tla_97UfE5KM","colab_type":"code","colab":{}},"source":["ALIGNMENT_DIR = 'data.PSE1'\n","CACHE_DIR = 'UNIREF_UNIPROT_RECORDS_PSE1'\n","OUTPUT_FILENAME = ALIGNMENT_DIR+'/PSE1_NATURAL_TAXONOMY.csv'\n","SEQUENCE_ALIGNMENT = ALIGNMENT_DIR+'/7fa1c5691376beab198788a726917d48_b0.4.a2m'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSxGxYKRE5KO","colab_type":"code","outputId":"2af72586-094d-40f8-dc28-0a8e9e4af2e0","colab":{}},"source":["#Load taxonomy IDS. \n","#  Note:  loaded 2208 uniref or uniprot records and saved them to the file system.\n","#         unable to recover 408 of the IDs in the PSE1 natural alignment (404 response\n","#         with uniref or blank response with uniprot)\n","pse1_df = getSequencenameTaxonomyidHM(SEQUENCE_ALIGNMENT, CACHE_DIR, local_cache_only=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["warning: unable to determine sequence record type: TARGET/1-266\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j8A29lzPE5KR","colab_type":"code","colab":{}},"source":["#output to csv\n","pd.concat([pse1_df, loadTaxonomyLineage(pse1_df.tax_id)], \n","          axis=1, \n","          sort=False).drop('seq_record', axis=1).to_csv(\n","    \n","    OUTPUT_FILENAME, sep='\\t', index=False\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmHsXCzKE5KU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}